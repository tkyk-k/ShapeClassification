{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fda0cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ShapeDataset(Dataset):\n",
    "    \"\"\"\n",
    "    è¤‡æ•°ã®æ‰‹æ›¸ãé¢¨å›³å½¢ï¼ˆå††ã€ä¸‰è§’å½¢ã€å››è§’å½¢ï¼‰ã‚’å«ã‚€ç”»åƒã¨ã€\n",
    "    ãã‚Œã«å¯¾å¿œã™ã‚‹ãƒ©ãƒ™ãƒ«æƒ…å ±ï¼ˆã‚¯ãƒ©ã‚¹ã€ä½ç½®ã€é¢ç©ï¼‰ã‚’èª­ã¿è¾¼ã‚€ PyTorch Dataset ã‚¯ãƒ©ã‚¹ã€‚\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, image_dir, label_dir, file_list):\n",
    "        \"\"\"\n",
    "        ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿\n",
    "\n",
    "        Args:\n",
    "            image_dir (str): ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ã¸ã®ãƒ‘ã‚¹ï¼ˆä¾‹ï¼š\"images\"ï¼‰\n",
    "            label_dir (str): ãƒ©ãƒ™ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ•ã‚©ãƒ«ãƒ€ã¸ã®ãƒ‘ã‚¹ï¼ˆä¾‹ï¼š\"labels\"ï¼‰\n",
    "            file_list (List[str]): å¯¾è±¡ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆæ‹¡å¼µå­ãªã—ï¼‰ã®ãƒªã‚¹ãƒˆï¼ˆä¾‹: ['img_0001', 'img_0002']ï¼‰\n",
    "        \"\"\"\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.file_list = file_list\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µã‚¤ã‚ºï¼ˆã‚µãƒ³ãƒ—ãƒ«æ•°ï¼‰ã‚’è¿”ã™\n",
    "\n",
    "        Returns:\n",
    "            int: ã‚µãƒ³ãƒ—ãƒ«æ•°ï¼ˆç”»åƒæ•°ï¼‰\n",
    "        \"\"\"\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        æŒ‡å®šã•ã‚ŒãŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ç”»åƒã¨ãƒ©ãƒ™ãƒ«ã‚’è¿”ã™\n",
    "\n",
    "        Args:\n",
    "            idx (int): ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹\n",
    "\n",
    "        Returns:\n",
    "            img (Tensor): æ­£è¦åŒ–ã•ã‚ŒãŸã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ç”»åƒ [1, H, W]\n",
    "            targets (Tensor): ãƒ©ãƒ™ãƒ«æƒ…å ± [num_shapes, 6]\n",
    "                              å„è¡Œã¯ [class_id, cx, cy, w, h, area]\n",
    "        \"\"\"\n",
    "        # ãƒ•ã‚¡ã‚¤ãƒ«åã®ãƒ™ãƒ¼ã‚¹ï¼ˆæ‹¡å¼µå­ãªã—ï¼‰ã‚’å–å¾—\n",
    "        base_name = self.file_list[idx]\n",
    "\n",
    "        # ç”»åƒã¨ãƒ©ãƒ™ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’æ§‹ç¯‰\n",
    "        img_path = os.path.join(self.image_dir, base_name + \".png\")\n",
    "        label_path = os.path.join(self.label_dir, base_name + \".txt\")\n",
    "\n",
    "        # ç”»åƒã‚’ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ã§èª­ã¿è¾¼ã¿ï¼ˆH, Wï¼‰ã€[0, 255] â†’ [0.0, 1.0] ã«å¤‰æ›\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE).astype(\"float32\") / 255.0\n",
    "\n",
    "        # [H, W] â†’ [1, H, W] ã«æ¬¡å…ƒè¿½åŠ ï¼ˆPyTorchã®å…¥åŠ›ã«åˆã‚ã›ã‚‹ï¼‰\n",
    "        img = torch.from_numpy(img).unsqueeze(0)\n",
    "\n",
    "        # ãƒ©ãƒ™ãƒ«ï¼ˆè¤‡æ•°å›³å½¢ï¼‰ã‚’èª­ã¿è¾¼ã‚“ã§ Tensor ã«å¤‰æ›\n",
    "        targets = []\n",
    "        with open(label_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                class_id = int(parts[0])  # ã‚¯ãƒ©ã‚¹ï¼ˆ0=å††, 1=ä¸‰è§’å½¢, 2=å››è§’å½¢ï¼‰\n",
    "                cx, cy, w, h, area = map(float, parts[1:])  # æ­£è¦åŒ–ã•ã‚ŒãŸä¸­å¿ƒåº§æ¨™ãƒ»ã‚µã‚¤ã‚ºãƒ»é¢ç©\n",
    "                targets.append([class_id, cx, cy, w, h, area])\n",
    "\n",
    "        # [num_shapes, 6] ã® Tensor ã«å¤‰æ›\n",
    "        targets = torch.tensor(targets, dtype=torch.float32)\n",
    "\n",
    "        return img, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e36e62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    imgs = torch.stack([item[0] for item in batch], dim=0)  # ç”»åƒã¯åŒã˜ã‚µã‚¤ã‚ºãªã®ã§stackå¯èƒ½\n",
    "    targets = [item[1] for item in batch]  # targetsã¯ãƒªã‚¹ãƒˆã®ã¾ã¾\n",
    "    return imgs, targets\n",
    "\n",
    "\"\"\"\n",
    "å­¦ç¿’ãƒ»æ¤œè¨¼ç”¨ã® DataLoader ã‚’æº–å‚™ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ\n",
    "åˆ†å‰²æ¸ˆã¿ã® dataset/train/ ã¨ dataset/val/ ã‚’å¯¾è±¡ã« Dataset ã‚’æ§‹ç¯‰\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹\n",
    "base_dir = \"dataset\"\n",
    "train_image_dir = os.path.join(base_dir, \"train\", \"images\")\n",
    "train_label_dir = os.path.join(base_dir, \"train\", \"labels\")\n",
    "val_image_dir = os.path.join(base_dir, \"val\", \"images\")\n",
    "val_label_dir = os.path.join(base_dir, \"val\", \"labels\")\n",
    "\n",
    "# ãƒ•ã‚¡ã‚¤ãƒ«åä¸€è¦§ï¼ˆæ‹¡å¼µå­ãªã—ï¼‰ã‚’å–å¾—\n",
    "train_files = [os.path.splitext(f)[0] for f in os.listdir(train_image_dir)]\n",
    "val_files   = [os.path.splitext(f)[0] for f in os.listdir(val_image_dir)]\n",
    "\n",
    "# ã‚½ãƒ¼ãƒˆã—ã¦ãŠãã¨é †åºãŒå®‰å®š\n",
    "train_files.sort()\n",
    "val_files.sort()\n",
    "\n",
    "# Dataset ã‚’ä½œæˆ\n",
    "train_dataset = ShapeDataset(train_image_dir, train_label_dir, train_files)\n",
    "val_dataset   = ShapeDataset(val_image_dir, val_label_dir, val_files)\n",
    "\n",
    "# DataLoader ã‚’ä½œæˆ\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "print(f\"âœ… DataLoader æº–å‚™å®Œäº†ï¼štrain={len(train_dataset)}æš / val={len(val_dataset)}æš\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae102d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class YOLOShapeDetector(nn.Module):\n",
    "    \"\"\"\n",
    "    ä»»æ„å€‹æ•°ã®å›³å½¢ï¼ˆå††ãƒ»ä¸‰è§’ãƒ»å››è§’ï¼‰ã‚’æ¤œå‡ºã™ã‚‹YOLOé¢¨ã®è»½é‡ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã€‚\n",
    "    1ã¤ã®å‡ºåŠ›ã‚»ãƒ«ã‚ãŸã‚Š Bå€‹ã®äºˆæ¸¬ãƒœãƒƒã‚¯ã‚¹ã‚’å‡ºåŠ›ã€‚\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, S=16, B=2, num_classes=3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            S (int): å‡ºåŠ›ã‚°ãƒªãƒƒãƒ‰ã®åˆ†å‰²æ•°ï¼ˆS x Sã‚»ãƒ«ï¼‰\n",
    "            B (int): 1ã‚»ãƒ«ã‚ãŸã‚Šã®äºˆæ¸¬ãƒœãƒƒã‚¯ã‚¹æ•°\n",
    "            num_classes (int): ã‚¯ãƒ©ã‚¹æ•°ï¼ˆä»Šå›ã¯ 3ï¼šå††ãƒ»ä¸‰è§’ãƒ»å››è§’ï¼‰\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.num_classes = num_classes\n",
    "        self.output_dim = B * (1 + 4 + num_classes + 1)  # objectness + bbox + class probs + area\n",
    "\n",
    "        # è»½é‡CNNãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding=1),  # å…¥åŠ›ã¯ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ç”»åƒ (1, H, W)\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 256x256\n",
    "\n",
    "            nn.Conv2d(16, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 128x128\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 64x64\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 32x32\n",
    "\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 16x16 â†’ S=16 ã«ä¸€è‡´\n",
    "        )\n",
    "\n",
    "        # å‡ºåŠ›å±¤ï¼šSÃ—Sã‚»ãƒ«ã”ã¨ã«Bå€‹ã®äºˆæ¸¬ï¼ˆobjectness + bbox + class + areaï¼‰\n",
    "        self.pred_head = nn.Conv2d(256, self.output_dim, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        å…¥åŠ›ç”»åƒã‹ã‚‰äºˆæ¸¬ã‚’å‡ºåŠ›\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): [B, 1, H, W] ã®ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ç”»åƒ\n",
    "\n",
    "        Returns:\n",
    "            Tensor: [B, S, S, B, 7 + num_classes] ã®äºˆæ¸¬\n",
    "        \"\"\"\n",
    "        feat = self.features(x)  # [B, 256, S, S]\n",
    "        out = self.pred_head(feat)  # [B, output_dim, S, S]\n",
    "\n",
    "        B, C, S, S = out.shape\n",
    "        out = out.permute(0, 2, 3, 1).contiguous()  # [B, S, S, output_dim]\n",
    "\n",
    "        out = out.view(B, S, S, self.B, -1)  # [B, S, S, B, 6 + num_classes]\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd165cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def compute_yolo_loss(preds, targets, S=16, B=2, num_classes=3, lambda_coord=5.0, lambda_noobj=0.5, lambda_area=1.0):\n",
    "    \"\"\"\n",
    "    YOLOå½¢å¼ã®ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯æå¤±é–¢æ•°ï¼ˆæœ¬ç•ªç”¨ï¼‰\n",
    "    - ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹å›å¸°ï¼ˆcx, cy, w, hï¼‰\n",
    "    - ã‚¯ãƒ©ã‚¹åˆ†é¡ï¼ˆã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ï¼‰\n",
    "    - é¢ç©å›å¸°ï¼ˆå›å¸°æå¤±ï¼‰\n",
    "    - objectnessï¼ˆäºŒå€¤åˆ†é¡ï¼‰\n",
    "\n",
    "    Args:\n",
    "        preds: Tensor [B, S, S, B, 1 + 4 + num_classes + 1]\n",
    "               ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›\n",
    "        targets: list[list]ï¼ˆå„ãƒãƒƒãƒã”ã¨ã®ãƒ©ãƒ™ãƒ«ãƒªã‚¹ãƒˆï¼‰\n",
    "               å„è¦ç´ ã¯ [class_id, cx, cy, w, h, area]\n",
    "        S: å‡ºåŠ›ã‚°ãƒªãƒƒãƒ‰æ•°ï¼ˆS Ã— Sï¼‰\n",
    "        B: å„ã‚°ãƒªãƒƒãƒ‰ã‚»ãƒ«ã‚ãŸã‚Šã®äºˆæ¸¬ãƒœãƒƒã‚¯ã‚¹æ•°\n",
    "        num_classes: å›³å½¢ã‚¯ãƒ©ã‚¹æ•°ï¼ˆå††ãƒ»ä¸‰è§’å½¢ãƒ»å››è§’å½¢ â†’ 3ï¼‰\n",
    "        lambda_coord: bboxå›å¸°ã®é‡ã¿ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5.0ï¼‰\n",
    "        lambda_noobj: objectnessãŒ0ã®ã‚»ãƒ«ã®æå¤±é‡ã¿ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.5ï¼‰\n",
    "        lambda_area: é¢ç©å›å¸°æå¤±ã®é‡ã¿ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1.0ï¼‰\n",
    "\n",
    "    Returns:\n",
    "        ç·åˆæå¤±ï¼ˆã‚¹ã‚«ãƒ©ãƒ¼ï¼‰\n",
    "    \"\"\"\n",
    "    \n",
    "    device = preds.device\n",
    "    batch_size = preds.shape[0]\n",
    "    loss = 0.0  # ç·æå¤±åˆæœŸåŒ–\n",
    "\n",
    "    for b in range(batch_size):\n",
    "        # 1ãƒãƒƒãƒåˆ†ã®ç©ºãƒ©ãƒ™ãƒ«ãƒ†ãƒ³ã‚½ãƒ«ã‚’æº–å‚™ï¼ˆäºˆæ¸¬ã¨åŒå½¢å¼ï¼‰\n",
    "        target_tensor = torch.zeros((S, S, B, 1 + 4 + num_classes + 1), device=device)\n",
    "\n",
    "        for t in targets[b]:\n",
    "            # ã‚¯ãƒ©ã‚¹ãƒ»ä½ç½®ãƒ»ã‚µã‚¤ã‚ºãƒ»é¢ç©ã‚’å–å¾—\n",
    "            class_id, cx, cy, w, h, area = t\n",
    "            class_id = int(class_id)\n",
    "\n",
    "            # å¯¾å¿œã™ã‚‹ã‚°ãƒªãƒƒãƒ‰ã‚»ãƒ«åº§æ¨™ã‚’å–å¾—ï¼ˆæ•´æ•°ï¼‰\n",
    "            grid_x = int(cx * S)\n",
    "            grid_y = int(cy * S)\n",
    "\n",
    "            # ã‚»ãƒ«å†…ã§ã®ç›¸å¯¾åº§æ¨™ï¼ˆ0ã€œ1ï¼‰\n",
    "            gx = cx * S - grid_x\n",
    "            gy = cy * S - grid_y\n",
    "\n",
    "            if grid_x >= S or grid_y >= S:\n",
    "                continue  # ç”»åƒå¤–ã«ã¯ç™»éŒ²ã—ãªã„ï¼ˆä¿é™ºï¼‰\n",
    "\n",
    "            # Bå€‹ã®æ ã®ã†ã¡ã€æœ€åˆã®ç©ºãã‚¹ãƒ­ãƒƒãƒˆã«ç™»éŒ²\n",
    "            for box in range(B):\n",
    "                if target_tensor[grid_y, grid_x, box, 0] == 0:\n",
    "                    # objectness = 1\n",
    "                    target_tensor[grid_y, grid_x, box, 0] = 1.0\n",
    "\n",
    "                    # bboxåº§æ¨™ï¼ˆã‚»ãƒ«å†…ï¼‰\n",
    "                    target_tensor[grid_y, grid_x, box, 1:5] = torch.tensor([gx, gy, w, h], device=device)\n",
    "\n",
    "                    # ã‚¯ãƒ©ã‚¹ one-hotï¼ˆä¾‹: [0,1,0]ï¼‰\n",
    "                    target_tensor[grid_y, grid_x, box, 5 + class_id] = 1.0\n",
    "\n",
    "                    # é¢ç©\n",
    "                    target_tensor[grid_y, grid_x, box, -1] = area\n",
    "                    break\n",
    "\n",
    "        # å¯¾è±¡ãƒãƒƒãƒã®äºˆæ¸¬ã¨ãƒ©ãƒ™ãƒ«ã‚’å–å¾—\n",
    "        pred = preds[b]     # [S, S, B, D]\n",
    "        target = target_tensor\n",
    "\n",
    "        # objectness ãƒã‚¹ã‚¯ï¼ˆç‰©ä½“ã‚ã‚Š / ãªã—ï¼‰\n",
    "        obj_mask = target[..., 0] == 1\n",
    "        noobj_mask = target[..., 0] == 0\n",
    "\n",
    "        # ---------- æå¤±è¨ˆç®— -----------\n",
    "\n",
    "        # 1. objectnessï¼ˆäºŒå€¤åˆ†é¡ï¼‰: BCE Loss\n",
    "        bce_obj = F.binary_cross_entropy_with_logits(\n",
    "            pred[..., 0], target[..., 0], reduction='none'\n",
    "        )\n",
    "        loss += (bce_obj * obj_mask).sum() + lambda_noobj * (bce_obj * noobj_mask).sum()\n",
    "\n",
    "        # 2. bboxï¼ˆå›å¸°ï¼‰: MSE Lossï¼ˆç‰©ä½“ãŒã‚ã‚‹å ´æ‰€ã ã‘ï¼‰\n",
    "        if obj_mask.any():\n",
    "            loss += lambda_coord * F.mse_loss(\n",
    "                pred[..., 1:5][obj_mask],\n",
    "                target[..., 1:5][obj_mask],\n",
    "                reduction='sum'\n",
    "            )\n",
    "\n",
    "            # 3. ã‚¯ãƒ©ã‚¹åˆ†é¡: Cross Entropyï¼ˆç‰©ä½“ãŒã‚ã‚‹å ´æ‰€ã ã‘ï¼‰\n",
    "            pred_cls = pred[..., 5:5+num_classes][obj_mask]               # [N, C]\n",
    "            target_cls = target[..., 5:5+num_classes][obj_mask]           # [N, C]\n",
    "            target_cls_ids = target_cls.argmax(dim=-1)                    # [N]\n",
    "            loss += F.cross_entropy(pred_cls, target_cls_ids, reduction='sum')\n",
    "\n",
    "            # 4. é¢ç©å›å¸°: MSE Lossï¼ˆç‰©ä½“ãŒã‚ã‚‹å ´æ‰€ã ã‘ï¼‰\n",
    "            pred_area = pred[..., -1][obj_mask]\n",
    "            target_area = target[..., -1][obj_mask]\n",
    "            loss += lambda_area * F.mse_loss(pred_area, target_area, reduction='sum')\n",
    "\n",
    "    return loss / batch_size  # ãƒãƒƒãƒå¹³å‡ã§æ­£è¦åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baae4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "'''\n",
    "# ãƒ¢ãƒ‡ãƒ«ã€æå¤±é–¢æ•°ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "from model import YOLOShapeDetector              # YOLOé¢¨ã®å›³å½¢æ¤œå‡ºãƒ¢ãƒ‡ãƒ«\n",
    "from loss import compute_yolo_loss              # ã‚«ã‚¹ã‚¿ãƒ æå¤±é–¢æ•°ï¼ˆåˆ†é¡ãƒ»å›å¸°ãƒ»é¢ç©ãƒ»objectnessï¼‰\n",
    "from dataset import ShapeDataset                # è‡ªä½œã®å›³å½¢ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¯ãƒ©ã‚¹\n",
    "'''\n",
    "\n",
    "# --- ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š ---\n",
    "S = 16                       # å‡ºåŠ›ã‚°ãƒªãƒƒãƒ‰æ•°ï¼ˆS x S ã«åˆ†å‰²ï¼‰\n",
    "B = 2                        # 1ã‚»ãƒ«ã‚ãŸã‚Šã®äºˆæ¸¬ãƒœãƒƒã‚¯ã‚¹æ•°\n",
    "num_classes = 3              # ã‚¯ãƒ©ã‚¹æ•°ï¼ˆå††ãƒ»ä¸‰è§’ãƒ»å››è§’ï¼‰\n",
    "input_size = 512             # å…¥åŠ›ç”»åƒã®ã‚µã‚¤ã‚ºï¼ˆç¸¦æ¨ªï¼‰\n",
    "batch_size = 8              # ãƒãƒƒãƒã‚µã‚¤ã‚º\n",
    "num_epochs = 10              # ç·ã‚¨ãƒãƒƒã‚¯æ•°\n",
    "learning_rate = 1e-3         # å­¦ç¿’ç‡\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹\n",
    "\n",
    "# --- ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼†ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆ ---\n",
    "\n",
    "# --- ãƒ¢ãƒ‡ãƒ«ã¨æœ€é©åŒ–ã®å®šç¾© ---\n",
    "model = YOLOShapeDetector(S=S, B=B, num_classes=num_classes).to(device)  # ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ï¼†GPUã¸è»¢é€\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)             # æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«Adamã‚’ä½¿ç”¨\n",
    "#scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5) \n",
    "\n",
    "# --- ãƒ­ã‚¹è¨˜éŒ²ç”¨ãƒªã‚¹ãƒˆ ---\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# --- å­¦ç¿’ãƒ«ãƒ¼ãƒ— ---\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "\n",
    "    for imgs, targets in train_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        preds = model(imgs)\n",
    "        loss = compute_yolo_loss(preds, targets, S=S, B=B, num_classes=num_classes)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # --- æ¤œè¨¼ãƒ«ãƒ¼ãƒ— ---\n",
    "    model.eval()  # æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆï¼ˆDropoutã‚„BatchNormã‚’ç„¡åŠ¹ã«ï¼‰\n",
    "    total_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for imgs, targets in val_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            preds = model(imgs)\n",
    "            loss = compute_yolo_loss(preds, targets, S=S, B=B, num_classes=num_classes)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    # --- ã‚¨ãƒãƒƒã‚¯ã”ã¨ã®çµæœè¡¨ç¤º ---\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "# --- ãƒ¢ãƒ‡ãƒ«ä¿å­˜ ---\n",
    "torch.save(model.state_dict(), \"shape_detector.pth\")\n",
    "print(\"âœ… ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: shape_detector.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d7a6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ãƒ­ã‚¹ã®å¯è¦–åŒ–ï¼ˆä»»æ„ï¼‰---\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(val_losses, label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig(\"loss_curve.png\")\n",
    "print(\"ğŸ“Š ãƒ­ã‚¹ã‚°ãƒ©ãƒ•ã‚’ loss_curve.png ã«ä¿å­˜ã—ã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f1fdeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1afeb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73109e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
